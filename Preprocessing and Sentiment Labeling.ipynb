{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "\n",
    "1. 원본 데이터 정리 (중복 제거, 빈 곳 삭제 등) 및 카테고라이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "def remove_emojis(text: str) -> str:\n",
    "    return ''.join(c for c in text if c not in emoji.UNICODE_EMOJI)\n",
    "\n",
    "file_name = '불러올 파일명'\n",
    "\n",
    "df = pd.read_excel(file_name)\n",
    "df = df.drop_duplicates(ignore_index = True)\n",
    "df = df.dropna(how='all',axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Okt를 통한 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "for i in range(len(df)):       \n",
    "    df.loc[i,'tokenized'] = str(okt.pos(remove_emojis(df.loc[i,'content']), norm=True, stem=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 불용어 제거 및 명사, 동사, 부사, 형용사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "tags = ['Noun', 'Verb', 'Adverb', 'Adjective']\n",
    "stopwords = ['하다', '없다', '있다', '되다', '아니다', '같다', '이다', '않다', '그렇다', \n",
    "             '이렇다', '싶다', '다', '것', '그', '이', '거']\n",
    "\n",
    "for i in range(len(df)):\n",
    "    pos_list = ast.literal_eval(df.loc[i, 'tokenized'])\n",
    "    \n",
    "    final = []\n",
    "    \n",
    "    for j in range(len(pos_list)):\n",
    "        if pos_list[j][1] in tags:\n",
    "            if pos_list[j][0] not in stopwords:\n",
    "                final.append(pos_list[j][0])\n",
    "    \n",
    "    df.loc[i, 'tokenized'] = str(final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 한국어 감성 사전 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/SentiWord_Dict.txt', 'r', -1, 'utf-8')\n",
    "lines = f.readlines()\n",
    "\n",
    "score_dict = []\n",
    "\n",
    "for line in lines:\n",
    "    line_splited = line.split()\n",
    "    score = int(line_splited[-1])\n",
    "    word = ''\n",
    "    for frac in line_splited[:-1]:\n",
    "        word = word + ' ' + frac\n",
    "    \n",
    "    word = word[1:]\n",
    "    score_dict.append([word, score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 감성 지수 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df['positive'] = 0\n",
    "df['negative'] = 0\n",
    "df['neutral'] = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    tokens = ast.literal_eval(df.loc[i, 'tokenized'])\n",
    "    for token in tokens:\n",
    "        for dict_word in score_dict:\n",
    "            if dict_word[0] == token:\n",
    "                if dict_word[1] > 0:\n",
    "                    df.loc[i, 'positive'] += dict_word[1]\n",
    "                elif dict_word[1] < 0:\n",
    "                    df.loc[i, 'negative'] += dict_word[1]\n",
    "                else:\n",
    "                    df.loc[i, 'neutral'] += 1 #중립어는 개수 세기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 지수에 따른 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = df['positive'] + df['negative']\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'score'] > 0:\n",
    "        label = 'Positive'\n",
    "    elif df.loc[i, 'score'] < 0:\n",
    "        label = 'Negative'\n",
    "    else:\n",
    "        label = 'Neutral'    \n",
    "    \n",
    "    df.loc[i, 'label'] = label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
